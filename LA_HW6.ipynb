{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining re-usable method to split matrix $A$ into sum of three matrices $L$, $D$ and $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDU_decomp(M):\n",
    "    L = np.tril(M, -1)\n",
    "    U = np.triu(M, 1)\n",
    "    D = np.diag(np.diag(M))\n",
    "    \n",
    "    return L, D, U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)\n",
    "\n",
    "Here I have defined single iteration for Jacobi method and overall method to execute Jacobi algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi_Iter_Single(Bj, dj, x_old): #single iteration of Jacobi method using pre-calculated matrix Bj and vector dj\n",
    "    x_new = np.dot(Bj, x_old) + dj\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def Jacobi_Iter (L, D, U, b, x0): #method for Jacobi iteration which uses single step method within\n",
    "    Bj = np.dot(-np.linalg.inv(D), (L+U)) #calculating matrix Bj using Jacobi method formula based on L, D and U input\n",
    "    dj = np.dot(np.linalg.inv(D), b) #calculating vector dj using Jacobi method formula based on D and b input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for Jacobi method\n",
    "        x_new = Jacobi_Iter_Single(Bj, dj, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Jacobi method executed for 10 iterations only:\n",
      "\n",
      "Error E=0.70711 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.70711\n",
      "\n",
      "Error E=0.50000 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.70711\n",
      "\n",
      "Error E=0.35355 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.70711\n",
      "\n",
      "Error E=0.25000 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.70711\n",
      "\n",
      "Error E=0.17678 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.70711\n",
      "\n",
      "Error E=0.12500 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.70711\n",
      "\n",
      "Error E=0.08839 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.70711\n",
      "\n",
      "Error E=0.06250 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.70711\n",
      "\n",
      "Error E=0.04419 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.70711\n",
      "\n",
      "Error E=0.03125 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.70711\n",
      "\n",
      "Solution for system Ax=b is x=[0.96875 0.96875 0.96875]\n",
      "Solution residual is 0.05413\n",
      "\n",
      "Spectral radius p(Bj)=1/sqrt(2)= 0.70711\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using Jacobi method executed for 10 iterations only:\")\n",
    "solution = Jacobi_Iter(L, D, U, b, x0)\n",
    "print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using Jacobi method\n",
    "print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "print(\"\\nSpectral radius p(Bj)=1/sqrt(2)= %.5f\" %(1/np.sqrt(2))) #printing spectral radius of Bj for convinience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Jacobi method decay rate dr equal to spectral radius $p(B_j)$ which is largest in absolute eigenvalue of matrix $B_j$. Sceptral radius $p(B_j)$ was calcualted in companion PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task(d)\n",
    "\n",
    "Here I have defined single iteration for Gauss-Seidel (GS) method and overall method to execute GS algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_Iter_Single(Bgs, dgs, x_old): #single iteration of GS method using pre-calculated matrix Bgs and vector dgs\n",
    "    x_new = np.dot(Bgs, x_old) + dgs\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def GS_Iter (L, D, U, b, x0): #method for GS iteration which uses single step method within\n",
    "    Bgs = np.dot(-np.linalg.inv(L+D), U) #calculating matrix Bgs using GS method formula based on L, D and U input\n",
    "    dgs = np.dot(np.linalg.inv(L+D), b) #calculating vector dgs using GS method formula based on L, D and b input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for GS method\n",
    "        x_new = GS_Iter_Single(Bgs, dgs, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Gauss-Seidel method executed for 10 iterations only:\n",
      "\n",
      "Error E=0.83853 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.83853\n",
      "\n",
      "Error E=0.43750 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.52175\n",
      "\n",
      "Error E=0.28125 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.64286\n",
      "\n",
      "Error E=0.14062 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.50000\n",
      "\n",
      "Error E=0.07031 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.50000\n",
      "\n",
      "Error E=0.03516 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.50000\n",
      "\n",
      "Error E=0.01758 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.50000\n",
      "\n",
      "Error E=0.00879 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.50000\n",
      "\n",
      "Error E=0.00439 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.50000\n",
      "\n",
      "Error E=0.00220 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.50000\n",
      "\n",
      "Solution for system Ax=b is x=[0.99854 0.99854 0.99927]\n",
      "Solution residual is 0.00220\n",
      "\n",
      "Spectral radius p(Bgs)=1/2= 0.50000\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using Gauss-Seidel method executed for 10 iterations only:\")\n",
    "solution = GS_Iter(L, D, U, b, x0)\n",
    "print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using GS method\n",
    "print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "print(\"\\nSpectral radius p(Bgs)=1/2= %.5f\" %(1/2)) #printing spectral radius of Bgs for convinience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gauss-Seidel (GS) method decay rate dr equal to spectral radius $p(B_{GS})$ which is largest in absolute eigenvalue of matrix $B_{GS}$. But this happens only from 4th iteration onwards. Till iteration 4, decay rate fluctuates around value 0.5 and eventually converges to it. From decay rate we could judge that overall convergens speed for GS method is higher that for Jacobi under same conditions. Spectral radius $p(B_{GS})=\\frac{1}{2}$ calculated in companion PDF file.\n",
    "\n",
    "Also worth to mentioned that solution retrieved by GS method is closer to true value after 10 iterations compare to Jacobi method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have defined single iteration for successive overrelaxation (SOR) method and overall method to execute SOR algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR_Iter_Single(Bsor, dsor, x_old): #single iteration of SOR method using pre-calculated matrix Bsor and vector dsor\n",
    "    x_new = np.dot(Bsor, x_old) + dsor\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def SOR_Iter (L, D, U, b, x0, w): #method for SOR iteration which uses single step method within\n",
    "    Bsor = np.dot(np.linalg.inv(w*L+D), ((1-w)*D-w*U)) #calculating matrix Bsor using SOR method formula based on L, D, U and w input\n",
    "    dsor = w*np.dot(np.linalg.inv(w*L+D), b) #calculating vector dsor using SOR method formula based on L, D, b and w input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    sr,_ = np.linalg.eig(Bsor)\n",
    "    sr = sr.max()\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for SOR method\n",
    "        x_new = SOR_Iter_Single(Bsor, dsor, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    \n",
    "    return x_new, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using successive overrelaxation method executed for 10 iterations only:\n",
      "Solving system with w=0.1\n",
      "\n",
      "Error E=0.07084 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.07084\n",
      "\n",
      "Error E=0.06444 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.90959\n",
      "\n",
      "Error E=0.05924 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.91928\n",
      "\n",
      "Error E=0.05499 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.92827\n",
      "\n",
      "Error E=0.05148 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.93629\n",
      "\n",
      "Error E=0.04856 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.94320\n",
      "\n",
      "Error E=0.04608 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.94898\n",
      "\n",
      "Error E=0.04395 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.95368\n",
      "\n",
      "Error E=0.04208 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.95743\n",
      "\n",
      "Error E=0.04041 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.96037\n",
      "\n",
      "Solution for system Ax=b is x=[0.34608 0.14725 0.3514 ]\n",
      "Solution residual is 1.25518\n",
      "\n",
      "Spectral radius for Bsor is p(Bsor)=0.96963 \n",
      "\n",
      "Solving system with w=1.1\n",
      "\n",
      "Error E=0.95247 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.95247\n",
      "\n",
      "Error E=0.46832 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.49169\n",
      "\n",
      "Error E=0.28992 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.61906\n",
      "\n",
      "Error E=0.09948 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.34312\n",
      "\n",
      "Error E=0.03877 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.38969\n",
      "\n",
      "Error E=0.01457 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.37578\n",
      "\n",
      "Error E=0.00553 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.37933\n",
      "\n",
      "Error E=0.00209 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.37839\n",
      "\n",
      "Error E=0.00079 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.37864\n",
      "\n",
      "Error E=0.00030 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.37857\n",
      "\n",
      "Solution for system Ax=b is x=[0.99987 0.99988 0.99995]\n",
      "Solution residual is 0.00018\n",
      "\n",
      "Spectral radius for Bsor is p(Bsor)=0.37859 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "ws=[0.1, 1.1] #setting list of given w values\n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using successive overrelaxation method executed for 10 iterations only:\")\n",
    "for w in ws:\n",
    "    print(\"Solving system with w=%s\" %w)\n",
    "    solution, sr = SOR_Iter(L, D, U, b, x0, w)\n",
    "    print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using GS method\n",
    "    print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "    print(\"\\nSpectral radius for Bsor is p(Bsor)=%.5f\" %sr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For successive overrelaxation (SOR) method decay rate dr equal to spectral radius $p(B_{SOR})$ which is largest in absolute eigenvalue of matrix $B_{SOR}$. Since I did not found this value manually in companion PDF file, I have used built-in function to find it. \n",
    "\n",
    "With $w=0.1$ convergence speed is slow, that is why solution found is quite far away from true value. This is indicated by respective norm. Also convergence speed is low because spectral radius is close to 1, it means with each iteration we have very minor improvement. We could notice it by observing respective errors. Finally, decay rate converges to spectral radius of $p(B_{SOR})$ only on iteration 10. So eventually system will be solved with $w=0.1$, but not within 10 iterations.\n",
    "\n",
    "For $w=1.1$ convergence speed is high. We could observe, that decay rate converges to spectral radius of $p(B_{SOR})$. But this happens only from 4th iteration onwards. Till iteration 4, decay rate fluctuates and eventually converges to spectral radius. From decay rate we could judge that overall convergens speed for SOR method is higher that for Jacobi and Gauss-Seidel methods under same conditions $p(B_{SOR})<p(B_{GS})<p(B_j)$. Also, worth to mentioned that solution retrieved by SOR method with $w=1.1$ is closer to true value after 10 iterations compare to Jacobi and GS methods.\n",
    "\n",
    "Successive overrelaxation (SOR) method has higher convergence speed compare to previous methods with $w>1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining auxilary mthod to create column vector from row vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colvec(rowvec):\n",
    "    v = np.asarray(rowvec)\n",
    "    return v.reshape(v.size,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)\n",
    "Here I defined iteration scheme for Jacobi method using formula I have written down in companion PDF file under Task (b) and test it for four different $\\alpha$ from convergence interval $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$. I choose two values from each sides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi_Alpha(x0, acc, alpha, u): #method to execute Jacobi method using formula I have write down in PDF Task (b)\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    \n",
    "    while True: #execute iteration until accuracy achieved\n",
    "\n",
    "        x_new = (1/(alpha+1))*(np.dot((-colvec(u)*u+np.identity(3)), x_old) + u) #formula written in Task (b)\n",
    "        if (np.linalg.norm(x_new - x_old) < acc): #stop execution if accuracy achieved - difference between new and old value less that accuracy\n",
    "            print(\"Solution found in %s\" %(iter+1), \"iterations with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new.round(5))\n",
    "            break\n",
    "        iter += 1\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Jacobi method executed untill accuracy 0.001 achieved:\n",
      "\n",
      "Solving for alpha = 2\n",
      "Solution found in 17 iterations with accuracy 0.001\n",
      "Solution is [ 0.2002 -0.2002  0.2002]\n",
      "\n",
      "Solving for alpha = -4\n",
      "Solution found in 17 iterations with accuracy 0.001\n",
      "Solution is [-0.99899  0.99899 -0.99899]\n",
      "\n",
      "Solving for alpha = 5\n",
      "Solution found in 7 iterations with accuracy 0.001\n",
      "Solution is [ 0.12506 -0.12506  0.12506]\n",
      "\n",
      "Solving for alpha = -7\n",
      "Solution found in 7 iterations with accuracy 0.001\n",
      "Solution is [-0.24989  0.24989 -0.24989]\n"
     ]
    }
   ],
   "source": [
    "u=np.array([1, -1, 1]) #setting vector u\n",
    "x0=np.array([0, 0, 0]) #setting x0 vector\n",
    "alphas = [2, -4, 5, -7] #list of possible alpha values\n",
    "acc = 0.001 #setting accuracy\n",
    "\n",
    "print(\"Solving system Ax=b using Jacobi method executed untill accuracy %.3f achieved:\" %acc)\n",
    "for alpha in alphas: #solving system with different values of alpha\n",
    "    print(\"\\nSolving for alpha = %.0f\" %alpha)\n",
    "    Jacobi_Alpha(x0, acc, alpha, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result of Jacobi method we could see that it converges faster when $\\alpha$ is further from edge of convergence range $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$. So that, the bigger difference between the faster solution will be found. You could spot that with $\\alpha=2$ or $\\alpha=-4$ it needs 17 iterations, but with 5 and -7 number of iterations become more than twise less - just 7.\n",
    "\n",
    "Also, formula I have written down in Task (b) is applicable and works properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d)\n",
    "Here I have defined iteration scheme for Gauss-Seidel method using formula I have written in Task (b) in companion PDF file. I test it with four different $\\alpha$ from convergence interval $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$. I choose two values from each sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_Alpha(x0, acc, alpha): #iteration method for Gass-Seidel\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    Bgs =  -1 * np.array([[0, -(alpha+1)**2, (alpha+1)**2], #writting down matrix Bgs as in Task (b) dependent from alpha value\n",
    "                                       [0, -(alpha+1), (alpha+1)-(alpha+1)**2], \n",
    "                                       [0, alpha, -2*alpha-1]])\n",
    "    \n",
    "    dgs=np.array([[(alpha+1)**2], [(alpha+1)-(alpha+1)**2], [-2*alpha-1+(alpha+1)**2]]) #same with dgs - writting it down as in Task(b) depending on alpha\n",
    "    \n",
    "    while True: #execute till accuracy achieved\n",
    "        \n",
    "        x_new = (1/(alpha+1)**3)*(np.dot(Bgs, colvec(x_old))+dgs) #calculating new value for x using formula from Taks (b)\n",
    "        if (np.linalg.norm(x_new - x_old) < acc): #if accuracy achieved stop execution - difference between new and old values less than accuracy\n",
    "            print(\"Solution found in %s\" %(iter+1), \"with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new.T.round(5))\n",
    "            break\n",
    "        iter += 1\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Gauss-Seidel method executed untill accuracy 0.001 achieved:\n",
      "\n",
      "Solving for alpha = 2\n",
      "Solution found in 5 with accuracy 0.001\n",
      "Solution is [[ 0.19979 -0.20002  0.20007]]\n",
      "\n",
      "Solving for alpha = -4\n",
      "Solution found in 10 with accuracy 0.001\n",
      "Solution is [[-0.99944  0.99957 -0.99967]]\n",
      "\n",
      "Solving for alpha = 5\n",
      "Solution found in 4 with accuracy 0.001\n",
      "Solution is [[ 0.12498 -0.125    0.125  ]]\n",
      "\n",
      "Solving for alpha = -7\n",
      "Solution found in 5 with accuracy 0.001\n",
      "Solution is [[-0.24998  0.24999 -0.24999]]\n"
     ]
    }
   ],
   "source": [
    "x0=np.array([0, 0, 0]) #setting initial x0\n",
    "alphas = [2, -4, 5, -7] #list possible values of alpha\n",
    "acc = 0.001 #setting accuracy\n",
    "\n",
    "print(\"Solving system Ax=b using Gauss-Seidel method executed untill accuracy %.3f achieved:\" %acc)\n",
    "for alpha in alphas: #solving system with different values of alpha\n",
    "    print(\"\\nSolving for alpha = %.0f\" %alpha)\n",
    "    GS_Alpha(x0, acc, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result of this method execution we could see that GS method converges faster than Jacobi method. For same values of $\\alpha$ we need less amount of iterations. Intresting observation - this method converges faster for positive values of $\\alpha$ than for negative. For example 2 and -4 are equaly away from edges of converges interval $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$, but method able to find correct solution with 2 times less iterations. Also, same as with Jacobi, the bigger difference between $\\alpha$ and edge of interval the faster method will converge to true solution value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (e)\n",
    "Here I have defined iteration scheme for successive overrelaxation (SOR) method using usuall formula and performing decomposition of $A$ nto $L$, $D$ and $U$. I test it with four different $\\alpha$ from convergence interval $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$. I choose two values from each sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR_Iter_Single(Bsor, dsor, x_old): #single iteration method for SOR\n",
    "    x_new = np.dot(Bsor, x_old) + dsor\n",
    "    return x_new\n",
    "\n",
    "def SOR_Iter (L, D, U, b, x0, w): #iteration method for SOR using single method within\n",
    "    Bsor = np.dot(np.linalg.inv(w*L+D), ((1-w)*D-w*U)) #calculatin matrix Bsor using usual formula\n",
    "    dsor = w*np.dot(np.linalg.inv(w*L+D), b) #calculatin vector dsor as per usual formula\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    \n",
    "    while True: #iterating over untill accuracy achieved - difference between new and old value les than accuracy\n",
    "        x_new = SOR_Iter_Single(Bsor, dsor, x_old) #calculating new value for x\n",
    "        if (np.linalg.norm(x_new - x_old) < acc): #stop eecution when accuracy achieved\n",
    "            print(\"Solution found in %s\" %(iter+1), \"with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new.T.round(5))\n",
    "            break\n",
    "        iter += 1 #updating old values\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using successive overrelaxation method executed untill accuracy 0.001 achieved:\n",
      "\n",
      "Solving for w=0.1 and alpha = 2\n",
      "Solution found in 24 with accuracy 0.001\n",
      "Solution is [ 0.19907 -0.19708  0.19508]\n",
      "\n",
      "Solving for w=0.1 and alpha = -4\n",
      "Solution found in 118 with accuracy 0.001\n",
      "Solution is [-0.98392  0.9841  -0.98429]\n",
      "\n",
      "Solving for w=0.1 and alpha = 5\n",
      "Solution found in 25 with accuracy 0.001\n",
      "Solution is [ 0.12176 -0.12128  0.1208 ]\n",
      "\n",
      "Solving for w=0.1 and alpha = -7\n",
      "Solution found in 50 with accuracy 0.001\n",
      "Solution is [-0.24237  0.24253 -0.24269]\n",
      "\n",
      "Solving for w=1.1 and alpha = 2\n",
      "Solution found in 5 with accuracy 0.001\n",
      "Solution is [ 0.20026 -0.19994  0.19991]\n",
      "\n",
      "Solving for w=1.1 and alpha = -4\n",
      "Solution found in 8 with accuracy 0.001\n",
      "Solution is [-0.99973  0.99981 -0.99987]\n",
      "\n",
      "Solving for w=1.1 and alpha = 5\n",
      "Solution found in 4 with accuracy 0.001\n",
      "Solution is [ 0.12507 -0.12508  0.125  ]\n",
      "\n",
      "Solving for w=1.1 and alpha = -7\n",
      "Solution found in 4 with accuracy 0.001\n",
      "Solution is [-0.24988  0.25001 -0.24998]\n"
     ]
    }
   ],
   "source": [
    "b=np.array([1, -1, 1]) #setting value of b\n",
    "x0=np.array([0, 0, 0]) #setting initial value of x0\n",
    "ws=[0.1, 1.1] #list possible values of w\n",
    "alphas = [2, -4, 5, -7] #list possible values of alpha\n",
    "acc = 0.001 #setting accuracy\n",
    "\n",
    "print(\"Solving system Ax=b using successive overrelaxation method executed untill accuracy %.3f achieved:\" %acc)\n",
    "for w in ws: #execute for each value of w\n",
    "    for alpha in alphas: #execute for each value of alpha\n",
    "        print(\"\\nSolving for w=%.1f\" %w, \"and alpha = %.0f\" %alpha)\n",
    "        A = np.array([[alpha+1, -1, 1], [-1, alpha+1, -1], [1, -1, alpha+1]]) #calculatin matrix A ase don alpha\n",
    "\n",
    "        L, D, U = LDU_decomp(A) #decompose A into L, D and U\n",
    "\n",
    "        SOR_Iter(L, D, U, b, x0, w) #execute SOR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result of this method execution we could see that successive overrelaxation method converges faster than Jacobi and Gauss-Seidel method when $w>1$ - for same values of $\\alpha$ we need less amount of iterations. Otherwise speed of convergence is slower as we could see with $w=0.1$.  Intresting observation - this method converges faster for positive values of $\\alpha$ than for negative. For example 2 and -4 are equaly away from edges of converges interval $\\alpha \\in (-\\infty; -3) \\cup (1; \\infty)$, but method able to find correct solution with 2 times less iterations. Also, same as with previous methods, the bigger difference between $\\alpha$ and edge of interval the faster method will converge to true solution value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have defined iteration algorithm for Conjugate Gradient method (CGM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGM(b, A, x0, acc): #iteratin algorithm for CGM\n",
    "    \n",
    "    x_old=x0#setting initial value for x0\n",
    "    r0 = b-np.dot(A, x_old) #setting value for residual r0\n",
    "    r_old=r0 #set initial residual and conjugate gradient values\n",
    "    p_old=r0\n",
    "    iter=0\n",
    "    \n",
    "    while True: #execute method until accuracy achieved\n",
    "        print(\"\\nIteration number %s\" %(iter+1))\n",
    "        alpha_k=(np.dot(np.transpose(r_old), r_old))/(np.dot(np.transpose(p_old),np.dot(A, p_old))) #calculating new alpha_k for current step as per CGM formula\n",
    "        x_new = x_old + np.dot(alpha_k, p_old) #calculating new value for x based on value of alpha_k calcualted above\n",
    "        print(\"Conjugate gradient is p=%s\" %p_old.round(5)) #printing out conjugate gradient of current iteration\n",
    "        r_new = r_old - alpha_k*np.dot(A, p_old) #calculating new residual\n",
    "        if (np.linalg.norm(r_new) < acc): #check if norm of new residual is less than accuracy\n",
    "            print(\"\\nSolution is %s\" %x_new, \"found in %s\" %(iter+1), \"iterations\")\n",
    "            break\n",
    "        beta = (np.dot(np.transpose(r_new), r_new))/(np.dot(np.transpose(r_old), r_old)) #calculating value for beta\n",
    "        p_new = r_new + np.dot(beta, p_old) #calculating new conjugate gradient to be used on next step\n",
    "        iter+=1 \n",
    "        x_old=x_new #updating old values for next iteration\n",
    "        r_old=r_new\n",
    "        p_old=p_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CGM defined above solving system given by $A=\\begin{pmatrix}2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2\n",
    "\t\\end{pmatrix}$ and $b=\\begin{pmatrix} \t1 \\\\ 0 \\\\ 1  \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b from Problem 1 using conjugate gradient method executed untill accuracy 0.001 achieved:\n",
      "\n",
      "Iteration number 1\n",
      "Conjugate gradient is p=[1 0 1]\n",
      "\n",
      "Iteration number 2\n",
      "Conjugate gradient is p=[0.5 1.  0.5]\n",
      "\n",
      "Solution is [1. 1. 1.] found in 2 iterations\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting matrix A as in Problem 1\n",
    "b=np.array([1, 0, 1]) #setting vector b\n",
    "x0=np.array([0, 0, 0]) #setting initial value for x0\n",
    "acc = 0.001 #setting accuracy.\n",
    "\n",
    "print(\"Solving system Ax=b from Problem 1 using conjugate gradient method executed untill accuracy %.3f achieved:\" %acc)\n",
    "CGM(b, A, x0, acc) #executing CGM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjugate gradient method converges to true solution very fast and with high precission. It only needs two iterations with conjugate gradients $p_1=\\begin{pmatrix} \t1 \\\\ 0 \\\\ 1  \\end{pmatrix}$ and $p_2=\\begin{pmatrix} \t1/2 \\\\ 1 \\\\ 1/2  \\end{pmatrix}$ to find a solution with given accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CGM defined above solving system given by $A=\\begin{pmatrix}\\alpha+1 & -1 & 1 \\\\ -1 & \\alpha+1 & -1 \\\\ 1 & -1 & \\alpha+1\n",
    "\t\\end{pmatrix}$ and $b=\\begin{pmatrix} \t1 \\\\ 0 \\\\ 1  \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b from Problem 2 using conjugate gradient method executed untill accuracy 0.001 achieved:\n",
      "\n",
      "Iteration number 1\n",
      "Conjugate gradient is p=[1 0 1]\n",
      "\n",
      "Iteration number 2\n",
      "Conjugate gradient is p=[0.22222 0.66667 0.22222]\n",
      "\n",
      "Solution is [0.5 0.5 0.5] found in 2 iterations\n"
     ]
    }
   ],
   "source": [
    "alpha=1 #setting value for alpha \n",
    "A = np.array([[alpha+1, -1, 1], [-1, alpha+1, -1], [1, -1, alpha+1]]) #setting matrix A as in Problem 2\n",
    "b=np.array([1, 0, 1]) #setting vector b\n",
    "x0=np.array([0, 0, 0]) #setting initial value for x0\n",
    "acc = 0.001 #setting accuracy.\n",
    "  \n",
    "print(\"Solving system Ax=b from Problem 2 using conjugate gradient method executed untill accuracy %.3f achieved:\" %acc)    \n",
    "CGM(b, A, x0, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, conjugate gradient method was able to find solution within 2 iterations and with hih precission. Conjugate gradients are $p_1=\\begin{pmatrix} \t1 \\\\ 0 \\\\ 1  \\end{pmatrix}$  and $p_2=\\begin{pmatrix} \t2/9 \\\\ 2/3 \\\\ 2/9  \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up matrix $A=PDP^{-1}$ for given $D=diag\\{1,2,3,4,5,6,7,8,9,10\\}$ and random matrix $P$ of size $10 \\times 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed=7 #setting random seed\n",
    "\n",
    "D = np.diag([1,2,3,4,5,6,7,8,9,10]) #defining matrix D\n",
    "\n",
    "# P = np.random.randint(1, 10, size=(10, 10))\n",
    "P=np.random.rand(10, 10) #creating random matrix P of size 10*10\n",
    "\n",
    "A4 = np.dot(np.dot(P, D),np.linalg.inv(P)) #calculating matrix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing power method to find dominating eigenvalue and corresponding eigenvector. To give possibility to compare this vector with the one found by other means I have to normalize it and make it unit vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_eigen(A, x0, acc): #defining power method algorithm\n",
    "    x_old=x0 #setting initial values \n",
    "    iter=0\n",
    "    alpha_k_old=0\n",
    "    \n",
    "    while True: #execute method until accuracy achieved\n",
    "        alpha_k=np.absolute(x_old).max() #choose maximum element in absolute of vector x_old as eigenvalue alpha_k\n",
    "        x_new = np.dot(A, x_old)/alpha_k #calculate new vector x based on old one, matrix A and alpha_k determined above\n",
    "        \n",
    "        if np.linalg.norm(alpha_k-alpha_k_old) < acc: #check if difference between new eigenvalue and old eigenvalue is less than accuracy\n",
    "            print(\"Solution found in %s\" %iter, \"iterations\")\n",
    "            print(\"Dominating eigenvalue is %.5f\" %alpha_k)\n",
    "            print(\"Dominating eigenvector is %s\" %((x_new/np.linalg.norm(x_new)).round(5))) #normalizing vector to make it unit vector\n",
    "            return alpha_k, x_new/np.linalg.norm(x_new)  #return dominating eigenvalue\n",
    "            break\n",
    "            \n",
    "        alpha_k_old=alpha_k #updating old values for next iteration\n",
    "        x_old=x_new\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found in 57 iterations\n",
      "Dominating eigenvalue is 9.99916\n",
      "Dominating eigenvector is [0.06778 0.26308 0.42104 0.35965 0.2179  0.27657 0.15477 0.44323 0.0301\n",
      " 0.52373]\n",
      "\n",
      "Checking result...\n",
      "Maximal eigenvalue via built-in function is 10.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed=7 #setting random seed\n",
    "# x0=np.random.randint(1, A4.shape[0], size=A4.shape[0])\n",
    "x0 = np.random.rand(A4.shape[0]) #setting initial value for x0\n",
    "acc=0.0001 #setting accuracy\n",
    "\n",
    "power_eigen(A4, x0, acc) #calling power method to find dominating eigenvalue\n",
    "\n",
    "print(\"\\nChecking result...\") #compare results with build-in python function to calcualte eigenvalues\n",
    "print(\"Maximal eigenvalue via built-in function is\", max(np.linalg.eig(A4)[0]).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power method able to find dominating eigenvalue and corresponding eigenvector with given accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining inverse power method which could find other eigenvalues based on some assumption value $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_power_eigen(A, mu, x0, acc): #defining inverse power method\n",
    "    Amu = (A-mu*np.identity(A.shape[0])) #calculating matrix (A-mu*I)\n",
    "    A_inv = np.linalg.inv(Amu) #inverting this matrix\n",
    "    \n",
    "    lambd_mu,_ = power_eigen(A_inv, x0, acc) #looking for dominating eigenvalue of matrix (A-mu*I)\n",
    "    \n",
    "    lambd = (1 + mu*lambd_mu)/lambd_mu #now performing calculation to identify corresponding eigenvalue of original matrix A\n",
    "    return lambd #returning closes eigenvalue of A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since biggest eigenvalue of matrix $A$ is equal 10 (denote it $\\lambda_{max}$), hence all other eigenvalues of lays in interval (-$\\lambda_{max}$; $\\lambda_{max}$). So that, to find all other eigenvalues we need to cycle through this interval with some step, then all other eigenvalues will be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serching for biggest eigenvalue...\n",
      "Solution found in 55 iterations\n",
      "Dominating eigenvalue is 9.99910\n",
      "Dominating eigenvector is [0.06793 0.26304 0.42103 0.3596  0.21801 0.27667 0.15477 0.44327 0.03018\n",
      " 0.52364]\n",
      "Range to search for remaining eigenvalues is (-9.99910; 9.99910)\n",
      "\n",
      "For mu=-10.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 21 iterations\n",
      "Dominating eigenvalue is 0.09077\n",
      "Dominating eigenvector is [-0.20913 -0.09907 -0.2496  -0.44481 -0.24392 -0.40911 -0.10638 -0.55223\n",
      " -0.29032 -0.24263]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.91769 \n",
      "\n",
      "For mu=-9.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 21 iterations\n",
      "Dominating eigenvalue is 0.09965\n",
      "Dominating eigenvector is [-0.21072 -0.1018  -0.24801 -0.44313 -0.24466 -0.40655 -0.11057 -0.55069\n",
      " -0.2927  -0.24711]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.93589 \n",
      "\n",
      "For mu=-8.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 21 iterations\n",
      "Dominating eigenvalue is 0.11048\n",
      "Dominating eigenvector is [-0.21231 -0.10409 -0.24661 -0.44131 -0.24554 -0.40411 -0.11431 -0.5492\n",
      " -0.29507 -0.25134]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.95227 \n",
      "\n",
      "For mu=-7.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 21 iterations\n",
      "Dominating eigenvalue is 0.12398\n",
      "Dominating eigenvector is [-0.21387 -0.1059  -0.24541 -0.4394  -0.24652 -0.40185 -0.11755 -0.5478\n",
      " -0.29737 -0.25526]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.96649 \n",
      "\n",
      "For mu=-6.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 21 iterations\n",
      "Dominating eigenvalue is 0.14130\n",
      "Dominating eigenvector is [-0.21534 -0.10723 -0.24444 -0.43751 -0.24754 -0.39983 -0.12023 -0.54653\n",
      " -0.29953 -0.25877]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.97823 \n",
      "\n",
      "For mu=-5.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 20 iterations\n",
      "Dominating eigenvalue is 0.16438\n",
      "Dominating eigenvector is [-0.21627 -0.10785 -0.24391 -0.43627 -0.24823 -0.39862 -0.12174 -0.54574\n",
      " -0.30088 -0.26089]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.98453 \n",
      "\n",
      "For mu=-4.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 19 iterations\n",
      "Dominating eigenvalue is 0.19649\n",
      "Dominating eigenvector is [-0.21719 -0.10832 -0.24345 -0.43503 -0.24894 -0.39749 -0.12308 -0.545\n",
      " -0.3022  -0.2629 ]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.99013 \n",
      "\n",
      "For mu=-3.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 18 iterations\n",
      "Dominating eigenvalue is 0.24427\n",
      "Dominating eigenvector is [-0.21801 -0.10862 -0.24309 -0.43389 -0.24961 -0.3965  -0.12418 -0.54433\n",
      " -0.30339 -0.26465]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.99469 \n",
      "\n",
      "For mu=-2.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 17 iterations\n",
      "Dominating eigenvalue is 0.32289\n",
      "Dominating eigenvector is [-0.21866 -0.10876 -0.24284 -0.43299 -0.25014 -0.39576 -0.12497 -0.54383\n",
      " -0.30431 -0.26598]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.99789 \n",
      "\n",
      "For mu=-1.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 15 iterations\n",
      "Dominating eigenvalue is 0.47655\n",
      "Dominating eigenvector is [-0.21898 -0.1088  -0.24273 -0.43254 -0.25041 -0.3954  -0.12532 -0.54358\n",
      " -0.30476 -0.26662]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.99934 \n",
      "\n",
      "For mu=-0.09910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 12 iterations\n",
      "Dominating eigenvalue is 0.90991\n",
      "Dominating eigenvector is [-0.2191  -0.1088  -0.24269 -0.43237 -0.25052 -0.39527 -0.12545 -0.54348\n",
      " -0.30493 -0.26687]\n",
      "\n",
      "Closes eigenvector aproximately equal to 0.99991 \n",
      "\n",
      "For mu=9.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 7 iterations\n",
      "Dominating eigenvalue is 9.91076\n",
      "Dominating eigenvector is [0.06557 0.26364 0.4212  0.36039 0.21634 0.27512 0.15479 0.44263 0.02894\n",
      " 0.52507]\n",
      "\n",
      "Closes eigenvector aproximately equal to 10.00000\n",
      "For mu=8.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 6 iterations\n",
      "Dominating eigenvalue is 9.91076\n",
      "Dominating eigenvector is [0.4918  0.05962 0.24384 0.08634 0.45915 0.47529 0.09798 0.41298 0.25582\n",
      " 0.07315]\n",
      "\n",
      "Closes eigenvector aproximately equal to 9.00000\n",
      "For mu=7.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 8 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [-0.03027 -0.1002  -0.49179 -0.29536 -0.27235 -0.151   -0.45414 -0.48846\n",
      " -0.03066 -0.34233]\n",
      "\n",
      "Closes eigenvector aproximately equal to 8.00000\n",
      "For mu=6.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 7 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [-0.45112 -0.3451  -0.05086 -0.2726  -0.18909 -0.42234 -0.38416 -0.11233\n",
      " -0.16848 -0.44475]\n",
      "\n",
      "Closes eigenvector aproximately equal to 7.00000\n",
      "For mu=5.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 8 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [0.0962  0.33418 0.35582 0.51627 0.16949 0.11784 0.30328 0.19871 0.34325\n",
      " 0.44049]\n",
      "\n",
      "Closes eigenvector aproximately equal to 6.00000\n",
      "For mu=4.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 7 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [-0.11844 -0.34808 -0.28361 -0.44386 -0.3785  -0.02544 -0.3001  -0.2977\n",
      " -0.4265  -0.28786]\n",
      "\n",
      "Closes eigenvector aproximately equal to 5.00000\n",
      "For mu=3.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 8 iterations\n",
      "Dominating eigenvalue is 9.91076\n",
      "Dominating eigenvector is [-1.7750e-01 -6.3414e-01 -8.0000e-05 -1.7620e-02 -3.2703e-01 -9.7480e-02\n",
      " -2.3980e-01 -4.7087e-01 -3.1272e-01 -2.6940e-01]\n",
      "\n",
      "Closes eigenvector aproximately equal to 4.00000\n",
      "For mu=2.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 7 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [0.13152 0.48061 0.05888 0.4548  0.10556 0.2455  0.3765  0.44606 0.20881\n",
      " 0.29271]\n",
      "\n",
      "Closes eigenvector aproximately equal to 3.00000\n",
      "For mu=1.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 8 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [0.35031 0.0797  0.13541 0.0763  0.35123 0.1118  0.27897 0.2816  0.49069\n",
      " 0.55948]\n",
      "\n",
      "Closes eigenvector aproximately equal to 2.00000\n",
      "For mu=0.89910:\n",
      "\n",
      "For inversed matrix:\n",
      "Solution found in 7 iterations\n",
      "Dominating eigenvalue is 9.91077\n",
      "Dominating eigenvector is [-0.21912 -0.1088  -0.24269 -0.43235 -0.25053 -0.39525 -0.12547 -0.54347\n",
      " -0.30495 -0.2669 ]\n",
      "\n",
      "Closes eigenvector aproximately equal to 1.00000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed=7 #setting random seed\n",
    "# mus = [4.8, 6.7, 5, 2]\n",
    "# mus = [8.1]\n",
    "# x0=np.random.randint(1, A4.shape[0], size=A4.shape[0])\n",
    "x0=np.random.rand(A4.shape[0]) #setting initial value of x0\n",
    "acc=0.0001 #setting accuracy\n",
    "\n",
    "print(\"Serching for biggest eigenvalue...\")\n",
    "alpha_max,_ = power_eigen(A4, x0, acc) #identifying range in which all other eigenvalues lies\n",
    "print(\"Range to search for remaining eigenvalues is (%.5f;\" %(-alpha_max), \"%.5f)\\n\" %alpha_max)\n",
    "\n",
    "mus = np.arange(-alpha_max-0.1, 0, 1) #creating range for negative part of interval\n",
    "\n",
    "for mu in mus: #executing for each value of mu in interval\n",
    "    print(\"For mu=%.5f:\" %mu)\n",
    "    print(\"\\nFor inversed matrix:\")\n",
    "    res = inverse_power_eigen(A4, mu, x0, acc) #calling inverse power method\n",
    "    print(\"\\nCloses eigenvector aproximately equal to %.5f \\n\" %res)\n",
    "    \n",
    "mus = np.arange(alpha_max-0.1, 0, -1) #creating range for positive part of interval\n",
    "\n",
    "for mu in mus: #executing for each value of mu in interval\n",
    "    print(\"For mu=%.5f:\" %mu)\n",
    "    print(\"\\nFor inversed matrix:\")\n",
    "    res = inverse_power_eigen(A4, mu, x0, acc) #calling inverse power method\n",
    "    print(\"\\nCloses eigenvector aproximately equal to %.5f\" %res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over negative and positive sides on interval gives us possibility to identify allpossible eigenvalues for matrix $A$. Since eigenvalues of $A$ known to us we could observe that all steps across negative side of interval produce eigenvalue 1, which is closest eigenvalue for given approxiamtions. For positive side of interval we are able to find all eigenvalues of $A$ with given approximations $\\mu$.\n",
    "\n",
    "Remark: In certain circumstances search accross negative interval produce eigenvalue of 2 instead of 1. My assumption - it happens when random generation of $x_0$ has certain zero values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up matrix $A=D+uu^T$ for given $D=diag\\{1,2,3,4,5,6,7,8,9,10\\}$ and random vector $u$ of size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed=7 #setting random seed value\n",
    "\n",
    "D = np.diag([1,2,3,4,5,6,7,8,9,10]) #setting matrix D\n",
    "\n",
    "# u=np.random.randint(1, D.shape[0], size=D.shape[0])\n",
    "\n",
    "u=np.random.rand(D.shape[0]) #setting random vector u\n",
    "\n",
    "A5 = D + colvec(u)*u #calculating matrix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)\n",
    "\n",
    "Implementing QR algorithm to find eigenvalues and eigenvectors of matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_eigens(A, acc): #QR algorithm implementation\n",
    "    A_old=A #setting initial matrix A\n",
    "    iter=0\n",
    "    EVcs=np.identity(A.shape[0]) #setting initial eigenvectors matrix as identity\n",
    "    \n",
    "    while True: #iterate unless accuracy achieved\n",
    "        Q, R = np.linalg.qr(A_old) #performing QR decomposition using built-in method of Python\n",
    "        A_new = np.dot(R, Q) #calculating new matrix A\n",
    "        EVcs = np.dot(EVcs, Q) #calculating eigenvectors matrix by multiplying by Q on each iteration\n",
    "        \n",
    "        if np.linalg.norm(A_new-A_old) < acc: #stop iterating if difference between new and old matrices is less than accuracy\n",
    "            print(\"Solution found in %s\" %(iter+1), \"iteration(s) with accuracy %s\" %acc)\n",
    "            print(\"\\nEigenvalues of matrix A are: \\n %s\" %np.diag(A_new).round(5))\n",
    "            EV_max = np.diag(A_new)[0] #returning dominating eigenvalue\n",
    "            print(\"\\nEigenvectors are: \\n %s\" %EVcs.round(5))\n",
    "            print(\"\\nDominating eigenvector is \\n %s\" %EVcs[:,0].round(5)) #printing out dominating eigenvector to compare with power method\n",
    "            EVc_max = EVcs[:,0]\n",
    "            return EV_max, EVc_max\n",
    "            break\n",
    "        \n",
    "        A_old=A_new #updating old values with new one\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding eigenvalues of A by using QR method executed untill accuracy 0.0001 achieved:\n",
      "\n",
      "Solution found in 87 iteration(s) with accuracy 0.0001\n",
      "\n",
      "Eigenvalues of matrix A are: \n",
      " [12.08524  9.33299  8.42792  7.10085  6.01127  5.14261  4.00768  3.08637\n",
      "  2.01013  1.58362]\n",
      "\n",
      "Eigenvectors are: \n",
      " [[-0.1448  -0.04241 -0.04826 -0.03146 -0.01551  0.06876  0.02328  0.12154\n",
      "   0.11214 -0.97008]\n",
      " [-0.01412 -0.00428 -0.00495 -0.00334 -0.00172  0.00804  0.00309  0.02071\n",
      "   0.99232  0.12063]\n",
      " [-0.05937 -0.01875 -0.02219 -0.01573 -0.00867  0.04468  0.02334  0.98653\n",
      "  -0.03845  0.13432]\n",
      " [-0.02174 -0.00726 -0.00886 -0.00678 -0.00423  0.0273   0.99848 -0.03039\n",
      "  -0.00623  0.02565]\n",
      " [-0.11154 -0.04016 -0.05149 -0.04498 -0.03819  0.98354 -0.03473 -0.06524\n",
      "  -0.01865  0.08159]\n",
      " [-0.03823 -0.01537 -0.0214  -0.02527 -0.99714 -0.0486  -0.00509 -0.01261\n",
      "  -0.00411  0.01858]\n",
      " [-0.16079 -0.07718 -0.12789 -0.9695   0.03999 -0.07812 -0.01192 -0.03301\n",
      "  -0.01156  0.05325]\n",
      " [-0.39394 -0.26595 -0.83999  0.21404  0.03914 -0.09995 -0.01758 -0.05174\n",
      "  -0.01896  0.08847]\n",
      " [-0.38631 -0.78774  0.46555  0.07505  0.01929 -0.05483 -0.01041 -0.03184\n",
      "  -0.01203  0.05668]\n",
      " [-0.79414  0.54654  0.23516  0.06831  0.02009 -0.0605  -0.01205 -0.03784\n",
      "  -0.01463  0.0694 ]]\n",
      "\n",
      "Dominating eigenvector is \n",
      " [-0.1448  -0.01412 -0.05937 -0.02174 -0.11154 -0.03823 -0.16079 -0.39394\n",
      " -0.38631 -0.79414]\n"
     ]
    }
   ],
   "source": [
    "acc=0.0001 #setting accuracy\n",
    "\n",
    "print(\"Finding eigenvalues of A by using QR method executed untill accuracy %.4f achieved:\\n\" %acc) \n",
    "EV_max, EVc_max = QR_eigens(A5, acc) #executing QR method for matrix A and storing dominating eigenvalue and corresponding eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QR method able to find all eigenvalues and eigenvectors of given matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I applying power method to the same matrix $A$ to compare results with QR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for eigenvalue using power method...\n",
      "Solution found in 35 iterations\n",
      "Dominating eigenvalue is 12.08550\n",
      "Dominating eigenvector is [0.1448  0.01412 0.05937 0.02174 0.11154 0.03823 0.1608  0.39396 0.38638\n",
      " 0.79409]\n",
      "\n",
      "Difference between dominating eigenvalues retrieved by QR and Power methods is 0.00026\n",
      "\n",
      "Difference between dominating eigenvectors retrieved by QR and Power methods is 0.00008\n"
     ]
    }
   ],
   "source": [
    "np.random.seed=7 #setting random seed\n",
    "# x0=np.random.randint(1, A5.shape[0], size=A5.shape[0])\n",
    "x0=np.random.rand(D.shape[0]) #setting initial value for x0\n",
    "acc=0.0001 #setting accuracy\n",
    "\n",
    "print(\"Looking for eigenvalue using power method...\")\n",
    "eigen_max, eigen_vector  = power_eigen(A5, x0, acc) #executing power method and store result\n",
    "\n",
    "#calculate norm of difference between eigenvalues found by QR and Power methods\n",
    "print(\"\\nDifference between dominating eigenvalues retrieved by QR and Power methods is %.5f\" %np.linalg.norm(eigen_max-EV_max))\n",
    "#calculate norm of difference between eigenvectors found by QR and Power methods\n",
    "print(\"\\nDifference between dominating eigenvectors retrieved by QR and Power methods is %.5f\" %np.linalg.norm(np.absolute(eigen_vector)-np.absolute(EVc_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from respective norms both methods are able to found dominating eigenvalue and respective eigenvector with given accuracy as results of execution are approximately same. Since vectors could be collinear I have to take their absolute values for norm calculation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
