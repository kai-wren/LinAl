{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining re-usable method to split matrix $A$ into sum of three matrices $L$, $D$ and $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDU_decomp(M):\n",
    "    L = np.tril(M, -1)\n",
    "    U = np.triu(M, 1)\n",
    "    D = np.diag(np.diag(M))\n",
    "    \n",
    "    return L, D, U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)\n",
    "\n",
    "Here I have defined single iteration for Jacobi method and overall method to execute Jacobi algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi_Iter_Single(Bj, dj, x_old): #single iteration of Jacobi method using pre-calculated matrix Bj and vector dj\n",
    "    x_new = np.dot(Bj, x_old) + dj\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def Jacobi_Iter (L, D, U, b, x0): #method for Jacobi iteration which uses single step method within\n",
    "    Bj = np.dot(-np.linalg.inv(D), (L+U)) #calculating matrix Bj using Jacobi method formula based on L, D and U input\n",
    "    dj = np.dot(np.linalg.inv(D), b) #calculating vector dj using Jacobi method formula based on D and b input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for Jacobi method\n",
    "        x_new = Jacobi_Iter_Single(Bj, dj, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Jacobi method executed for 10 iterations only:\n",
      "\n",
      "Error E=0.70711 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.70711\n",
      "\n",
      "Error E=0.50000 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.70711\n",
      "\n",
      "Error E=0.35355 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.70711\n",
      "\n",
      "Error E=0.25000 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.70711\n",
      "\n",
      "Error E=0.17678 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.70711\n",
      "\n",
      "Error E=0.12500 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.70711\n",
      "\n",
      "Error E=0.08839 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.70711\n",
      "\n",
      "Error E=0.06250 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.70711\n",
      "\n",
      "Error E=0.04419 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.70711\n",
      "\n",
      "Error E=0.03125 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.70711\n",
      "\n",
      "Solution for system Ax=b is x=[0.96875 0.96875 0.96875]\n",
      "Solution residual is 0.05413\n",
      "\n",
      "Spectral radius p(Bj)=1/sqrt(2)= 0.70711\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using Jacobi method executed for 10 iterations only:\")\n",
    "solution = Jacobi_Iter(L, D, U, b, x0)\n",
    "print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using Jacobi method\n",
    "print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "print(\"\\nSpectral radius p(Bj)=1/sqrt(2)= %.5f\" %(1/np.sqrt(2))) #printing spectral radius of Bj for convinience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Jacobi method decay rate dr equal to spectral radius $p(B_j)$ which is largest in absolute eigenvalue of matrix $B_j$. Sceptral radius $p(B_j)$ was calcualted in companion PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task(d)\n",
    "\n",
    "Here I have defined single iteration for Gauss-Seidel (GS) method and overall method to execute GS algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_Iter_Single(Bgs, dgs, x_old): #single iteration of GS method using pre-calculated matrix Bgs and vector dgs\n",
    "    x_new = np.dot(Bgs, x_old) + dgs\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def GS_Iter (L, D, U, b, x0): #method for GS iteration which uses single step method within\n",
    "    Bgs = np.dot(-np.linalg.inv(L+D), U) #calculating matrix Bgs using GS method formula based on L, D and U input\n",
    "    dgs = np.dot(np.linalg.inv(L+D), b) #calculating vector dgs using GS method formula based on L, D and b input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for GS method\n",
    "        x_new = GS_Iter_Single(Bgs, dgs, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using Gauss-Seidel method executed for 10 iterations only:\n",
      "\n",
      "Error E=0.83853 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.83853\n",
      "\n",
      "Error E=0.43750 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.52175\n",
      "\n",
      "Error E=0.28125 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.64286\n",
      "\n",
      "Error E=0.14062 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.50000\n",
      "\n",
      "Error E=0.07031 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.50000\n",
      "\n",
      "Error E=0.03516 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.50000\n",
      "\n",
      "Error E=0.01758 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.50000\n",
      "\n",
      "Error E=0.00879 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.50000\n",
      "\n",
      "Error E=0.00439 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.50000\n",
      "\n",
      "Error E=0.00220 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.50000\n",
      "\n",
      "Solution for system Ax=b is x=[0.99854 0.99854 0.99927]\n",
      "Solution residual is 0.00220\n",
      "\n",
      "Spectral radius p(Bgs)=1/2= 0.50000\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using Gauss-Seidel method executed for 10 iterations only:\")\n",
    "solution = GS_Iter(L, D, U, b, x0)\n",
    "print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using GS method\n",
    "print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "print(\"\\nSpectral radius p(Bgs)=1/2= %.5f\" %(1/2)) #printing spectral radius of Bgs for convinience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gauss-Seidel (GS) method decay rate dr equal to spectral radius $p(B_{GS})$ which is largest in absolute eigenvalue of matrix $B_{GS}$. But this happens only from 4th iteration onwards. Till iteration 4, decay rate fluctuates around value 0.5 and eventually converges to it. From decay rate we could judge that overall convergens speed for GS method is higher that for Jacobi under same conditions. Spectral radius $p(B_{GS})=\\frac{1}{2}$ calculated in companion PDF file.\n",
    "\n",
    "Also worth to mentioned that solution retrieved by GS method is closer to true value after 10 iterations compare to Jacobi method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have defined single iteration for successive overrelaxation (SOR) method and overall method to execute SOR algorithm for 10 iterations. On each step, we check Euclidian norm to compare old and new solution and determine error $E_k$.\n",
    "\n",
    "Decay rate $dr$ could be found using formula $dr = \\frac{E_k}{E_{k-1}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR_Iter_Single(Bsor, dsor, x_old): #single iteration of SOR method using pre-calculated matrix Bsor and vector dsor\n",
    "    x_new = np.dot(Bsor, x_old) + dsor\n",
    "    return x_new #return of method is new value for x\n",
    "\n",
    "def SOR_Iter (L, D, U, b, x0, w): #method for SOR iteration which uses single step method within\n",
    "    Bsor = np.dot(np.linalg.inv(w*L+D), ((1-w)*D-w*U)) #calculating matrix Bsor using SOR method formula based on L, D, U and w input\n",
    "    dsor = w*np.dot(np.linalg.inv(w*L+D), b) #calculating vector dsor using SOR method formula based on L, D, b and w input\n",
    "    x_old = x0 #setting x0 to start with first iteration\n",
    "    E_old = 1 #setting initial value for old error E value\n",
    "    sr,_ = np.linalg.eig(Bsor)\n",
    "    sr = sr.max()\n",
    "    \n",
    "    for i in range(0, 10): #performing 10 iterations for SOR method\n",
    "        x_new = SOR_Iter_Single(Bsor, dsor, x_old) #calling single step method to calculate new value for x\n",
    "        E = np.linalg.norm(x_new - x_old) #calculating error between old and new values of x using Euclidian norm\n",
    "        dr = E/E_old #calculating decay rate dr as relation between current and previous steps error\n",
    "        print(\"\\nError E=%.5f\" %E, \"for iteration %s\" %(i+1))\n",
    "        print(\"Decay rate for iteration %s\" %(i+1), \"equal to %.5f\" %dr)\n",
    "        \n",
    "        #updating old values for next iteration \n",
    "        E_old = E\n",
    "        x_old = x_new\n",
    "    \n",
    "    return x_new, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving system Ax=b using successive overrelaxation method executed for 10 iterations only:\n",
      "Solving system with w=0.1\n",
      "\n",
      "Error E=0.07084 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.07084\n",
      "\n",
      "Error E=0.06444 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.90959\n",
      "\n",
      "Error E=0.05924 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.91928\n",
      "\n",
      "Error E=0.05499 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.92827\n",
      "\n",
      "Error E=0.05148 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.93629\n",
      "\n",
      "Error E=0.04856 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.94320\n",
      "\n",
      "Error E=0.04608 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.94898\n",
      "\n",
      "Error E=0.04395 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.95368\n",
      "\n",
      "Error E=0.04208 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.95743\n",
      "\n",
      "Error E=0.04041 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.96037\n",
      "\n",
      "Solution for system Ax=b is x=[0.34608 0.14725 0.3514 ]\n",
      "Solution residual is 1.25518\n",
      "\n",
      "Spectral radius for Bsor is p(Bsor)=0.96963 \n",
      "\n",
      "Solving system with w=1.1\n",
      "\n",
      "Error E=0.95247 for iteration 1\n",
      "Decay rate for iteration 1 equal to 0.95247\n",
      "\n",
      "Error E=0.46832 for iteration 2\n",
      "Decay rate for iteration 2 equal to 0.49169\n",
      "\n",
      "Error E=0.28992 for iteration 3\n",
      "Decay rate for iteration 3 equal to 0.61906\n",
      "\n",
      "Error E=0.09948 for iteration 4\n",
      "Decay rate for iteration 4 equal to 0.34312\n",
      "\n",
      "Error E=0.03877 for iteration 5\n",
      "Decay rate for iteration 5 equal to 0.38969\n",
      "\n",
      "Error E=0.01457 for iteration 6\n",
      "Decay rate for iteration 6 equal to 0.37578\n",
      "\n",
      "Error E=0.00553 for iteration 7\n",
      "Decay rate for iteration 7 equal to 0.37933\n",
      "\n",
      "Error E=0.00209 for iteration 8\n",
      "Decay rate for iteration 8 equal to 0.37839\n",
      "\n",
      "Error E=0.00079 for iteration 9\n",
      "Decay rate for iteration 9 equal to 0.37864\n",
      "\n",
      "Error E=0.00030 for iteration 10\n",
      "Decay rate for iteration 10 equal to 0.37857\n",
      "\n",
      "Solution for system Ax=b is x=[0.99987 0.99988 0.99995]\n",
      "Solution residual is 0.00018\n",
      "\n",
      "Spectral radius for Bsor is p(Bsor)=0.37859 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]]) #setting given matrix A\n",
    "b=np.array([1, 0, 1]) #setting given vector b\n",
    "x0=np.array([0, 0, 0]) #setting given starting vector x0 \n",
    "ws=[0.1, 1.1] #setting list of given w values\n",
    "\n",
    "L, D, U = LDU_decomp(A) #retriving L, D and U matrices\n",
    "\n",
    "print(\"Solving system Ax=b using successive overrelaxation method executed for 10 iterations only:\")\n",
    "for w in ws:\n",
    "    print(\"Solving system with w=%s\" %w)\n",
    "    solution, sr = SOR_Iter(L, D, U, b, x0, w)\n",
    "    print(\"\\nSolution for system Ax=b is x=%s\" %solution.round(5)) #solution found using GS method\n",
    "    print(\"Solution residual is %.5f\" %np.linalg.norm([1, 1, 1]-solution))\n",
    "    print(\"\\nSpectral radius for Bsor is p(Bsor)=%.5f\" %sr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For successive overrelaxation (SOR) method decay rate dr equal to spectral radius $p(B_{SOR})$ which is largest in absolute eigenvalue of matrix $B_{SOR}$. Since I did not found this value manually in companion PDF file, I have used built-in function to find it. \n",
    "\n",
    "With $w=0.1$ convergence speed is slow, that is why solution found is quite far away from true value. This is indicated by respective norm. Also convergence speed is low because spectral radius is close to 1, it means with each iteration we have very minor improvement. We could notice it by observing respective errors. Finally, decay rate converges to spectral radius of $p(B_{SOR})$ only on iteration 10. So eventually system will be solved with $w=0.1$, but not within 10 iterations.\n",
    "\n",
    "For $w=1.1$ convergence speed is high. We could observe, that decay rate converges to spectral radius of $p(B_{SOR})$. But this happens only from 4th iteration onwards. Till iteration 4, decay rate fluctuates and eventually converges to spectral radius. From decay rate we could judge that overall convergens speed for SOR method is higher that for Jacobi and Gauss-Seidel methods under same conditions $p(B_{SOR})<p(B_{GS})<p(B_j)$. Also, worth to mentioned that solution retrieved by SOR method with $w=1.1$ is closer to true value after 10 iterations compare to Jacobi and GS methods.\n",
    "\n",
    "Successive overrelaxation (SOR) method has higher convergence speed compare to previous methods with $w>1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colvec(rowvec):\n",
    "    v = np.asarray(rowvec)\n",
    "    return v.reshape(v.size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi_Alpha(x0, acc, alpha, u):\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    \n",
    "    while True:\n",
    "#         print('Iteration=', iter)\n",
    "        x_new = (1/(alpha+1))*(np.dot((-colvec(u)*u+np.identity(3)), x_old) + u)\n",
    "#         print('1=',(1/(alpha+1)))\n",
    "#         print('2=', np.dot((colvec(u)*u+np.identity(3)), x_old))\n",
    "#         print('3=', u)\n",
    "#         print('4=', x_new)\n",
    "#         print(np.linalg.norm(x_new - x_old))\n",
    "        if (np.linalg.norm(x_new - x_old) < acc) and (iter > 0):\n",
    "            print(\"Solution found in %s\" %(iter+1), \"iterations with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new)\n",
    "            break\n",
    "        iter += 1\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u=np.array([1, -1, 1])\n",
    "x0=np.array([0, 0, 0])\n",
    "alphas = [2, -4, 5, -7]\n",
    "acc = 0.001\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha = %.0f\" %alpha)\n",
    "    Jacobi_Alpha(x0, acc, alpha, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_Alpha(x0, acc, alpha):\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    Bgs =  -1 * np.array([[0, -(alpha+1)**2, (alpha+1)**2], \n",
    "                                       [0, -(alpha+1), (alpha+1)-(alpha+1)**2], \n",
    "                                       [0, alpha, -2*alpha-1]])\n",
    "    \n",
    "    dgs=np.array([[(alpha+1)**2], [(alpha+1)-(alpha+1)**2], [-2*alpha-1+(alpha+1)**2]])\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        x_new = (1/(alpha+1)**3)*(np.dot(Bgs, colvec(x_old))+dgs)\n",
    "#         print(np.dot(Bgs, colvec(x_old)))\n",
    "#         print(x_new)\n",
    "        if (np.linalg.norm(x_new - x_old) < acc) and (iter > 0):\n",
    "            print(\"Solution found in %s\" %(iter+1), \"with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new.T)\n",
    "            break\n",
    "        iter += 1\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0=np.array([0, 0, 0])\n",
    "alphas = [2, -4, 5, -7]\n",
    "acc = 0.001\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha = %.0f\" %alpha)\n",
    "    GS_Alpha(x0, acc, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR_Iter_Single(Bsor, dsor, x_old):\n",
    "    x_new = np.dot(Bsor, x_old) + dsor\n",
    "    return x_new\n",
    "\n",
    "def SOR_Iter (L, D, U, b, x0, w):\n",
    "    Bsor = np.dot(np.linalg.inv(w*L+D), ((1-w)*D-w*U))\n",
    "    dsor = w*np.dot(np.linalg.inv(w*L+D), b)\n",
    "    x_old = x0\n",
    "    iter = 0\n",
    "    \n",
    "    while True:\n",
    "        x_new = SOR_Iter_Single(Bsor, dsor, x_old)\n",
    "#         print(x_new)\n",
    "#         print(np.linalg.norm(x_new - x_old))\n",
    "        if (np.linalg.norm(x_new - x_old) < acc) and (iter > 0):\n",
    "            print(\"Solution found in %s\" %(iter+1), \"with accuracy %.3f\" %acc)\n",
    "            print(\"Solution is %s\" %x_new.T)\n",
    "            break\n",
    "        iter += 1\n",
    "        x_old = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([1, -1, 1])\n",
    "x0=np.array([0, 0, 0])\n",
    "ws=[0.1, 1.1]\n",
    "alphas = [2, -4, 5, -7]\n",
    "acc = 0.001\n",
    "\n",
    "for w in ws:\n",
    "    print(\"For w=%.f\" %w)\n",
    "    for alpha in alphas:\n",
    "        print(\"Alpha = %.0f\" %alpha)\n",
    "        A = np.array([[alpha+1, -1, 1], [-1, alpha+1, -1], [1, -1, alpha+1]])\n",
    "\n",
    "        L, D, U = LDU_matrixes(A)\n",
    "\n",
    "        SOR_Iter(L, D, U, b, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGM(b, A, x0, acc):\n",
    "    \n",
    "    x_old=x0\n",
    "    r0 = b-np.dot(A, x_old)\n",
    "    r_old=r0\n",
    "    p_old=r0\n",
    "    iter=0\n",
    "    \n",
    "    while True:\n",
    "        print(\"Iteration %s\" %iter)\n",
    "        alpha_k=(np.dot(np.transpose(r_old), r_old))/(np.dot(np.transpose(p_old),np.dot(A, p_old)))\n",
    "        x_new = x_old + np.dot(alpha_k, p_old)\n",
    "        print(\"Conjugate gradient is p=%s\" %p_old)\n",
    "        r_new = r_old - alpha_k*np.dot(A, p_old)\n",
    "        if (np.linalg.norm(r_new) < acc):\n",
    "            print(\"Solution is %s\" %x_new, \"found in %s\" %(iter+1), \"iterations\")\n",
    "            break\n",
    "        beta = (np.dot(np.transpose(r_new), r_new))/(np.dot(np.transpose(r_old), r_old))\n",
    "        p_new = r_new + np.dot(beta, p_old)\n",
    "        iter+=1\n",
    "        x_old=x_new\n",
    "        r_old=r_new\n",
    "        p_old=p_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])\n",
    "b=np.array([1, 0, 1])\n",
    "x0=np.array([0, 0, 0])\n",
    "acc = 0.001\n",
    "        \n",
    "CGM(b, A, x0, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=1\n",
    "A = np.array([[alpha+1, -1, 1], [-1, alpha+1, -1], [1, -1, alpha+1]])\n",
    "b=np.array([1, 0, 1])\n",
    "x0=np.array([0, 0, 0])\n",
    "acc = 0.001\n",
    "        \n",
    "CGM(b, A, x0, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed=7\n",
    "\n",
    "D = np.diag([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# P = np.random.randint(1, 10, size=(10, 10))\n",
    "P=np.random.rand(10, 10)\n",
    "\n",
    "A4 = np.dot(np.dot(P, D),np.linalg.inv(P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_eigen(A, x0, acc):\n",
    "    x_old=x0\n",
    "    iter=0\n",
    "    alpha_k_old=0\n",
    "    \n",
    "    while True:\n",
    "        alpha_k=np.absolute(x_old).max()\n",
    "        x_new = np.dot(A, x_old)/alpha_k\n",
    "        \n",
    "        if np.linalg.norm(alpha_k-alpha_k_old) < acc:\n",
    "            print(\"Solution found in %s\" %iter, \"iterations\")\n",
    "            print(\"Dominating eigenvalue is %.5f\" %alpha_k)\n",
    "            print(\"Dominating eigenvector is %s\" %((x_new/np.linalg.norm(x_new)).round(4)))\n",
    "            return alpha_k\n",
    "            break\n",
    "            \n",
    "        alpha_k_old=alpha_k\n",
    "        x_old=x_new\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed=7\n",
    "# x0=np.random.randint(1, A4.shape[0], size=A4.shape[0])\n",
    "x0 = np.random.rand(A4.shape[0])\n",
    "acc=0.0001\n",
    "\n",
    "power_eigen(A4, x0, acc)\n",
    "\n",
    "print(\"Checking result...\")\n",
    "print(\"Maximal eigenvalue via built-in function is \", max(np.linalg.eig(A4)[0]).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_power_eigen(A, mu, x0, acc):\n",
    "    Amu = (A-mu*np.identity(A.shape[0]))\n",
    "    A_inv = np.linalg.inv(Amu)\n",
    "    \n",
    "    lambd_mu = power_eigen(A_inv, x0, acc)\n",
    "    \n",
    "    lambd = (1 + mu*lambd_mu)/lambd_mu\n",
    "    return lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed=7\n",
    "# mus = [4.8, 6.2, 7.5, 2.5]\n",
    "mus = [8]\n",
    "# x0=np.random.randint(1, A4.shape[0], size=A4.shape[0])\n",
    "x0=np.random.rand(A4.shape[0])\n",
    "acc=0.0001\n",
    "\n",
    "for mu in mus:\n",
    "    print(\"For inversed matrix:\")\n",
    "    res = inverse_power_eigen(A4, mu, x0, acc)\n",
    "    print(\"Closes eigenvector aproximately equal to %.5f\" %res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed=7\n",
    "\n",
    "D = np.diag([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# u=np.random.randint(1, D.shape[0], size=D.shape[0])\n",
    "\n",
    "u=np.random.rand(D.shape[0])\n",
    "\n",
    "A5 = D + colvec(u)*u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_eigens(A, acc):\n",
    "    A_old=A\n",
    "    iter=0\n",
    "    EVcs=np.identity(A.shape[0])\n",
    "    \n",
    "    while True:\n",
    "        Q, R = np.linalg.qr(A_old)\n",
    "        A_new = np.dot(R, Q)\n",
    "        if iter == 0:\n",
    "            EVcs = Q\n",
    "        else:\n",
    "            EVcs = np.dot(EVcs, Q)\n",
    "        \n",
    "        if np.linalg.norm(A_new-A_old) < acc:\n",
    "            print(\"Solution found in %s\" %(iter+1), \"iteration(s) with accuracy %s\" %acc)\n",
    "            print(\"Eigenvalues of matrix A are: \\n %s\" %np.diag(A_new).round(4))\n",
    "            print(\"Eigenvectors are: \\n %s\" %EVcs.round(4))\n",
    "            break\n",
    "        \n",
    "        A_old=A_new\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc=0.0001\n",
    "\n",
    "QR_eigens(A5, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed=7\n",
    "x0=np.random.randint(1, A5.shape[0], size=A5.shape[0])\n",
    "acc=0.0001\n",
    "\n",
    "power_eigen(A5, x0, acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
